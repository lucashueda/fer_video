{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import das libs utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as k \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo a base tratada no notebook de preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>key_img</th>\n",
       "      <th>frame</th>\n",
       "      <th>dir_lbl</th>\n",
       "      <th>label</th>\n",
       "      <th>cat_labels</th>\n",
       "      <th>reduced_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extended-cohn-kanade-images\\cohn-kanade-images...</td>\n",
       "      <td>S005001</td>\n",
       "      <td>1</td>\n",
       "      <td>Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extended-cohn-kanade-images\\cohn-kanade-images...</td>\n",
       "      <td>S005001</td>\n",
       "      <td>2</td>\n",
       "      <td>Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extended-cohn-kanade-images\\cohn-kanade-images...</td>\n",
       "      <td>S005001</td>\n",
       "      <td>3</td>\n",
       "      <td>Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extended-cohn-kanade-images\\cohn-kanade-images...</td>\n",
       "      <td>S005001</td>\n",
       "      <td>4</td>\n",
       "      <td>Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>disgust</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extended-cohn-kanade-images\\cohn-kanade-images...</td>\n",
       "      <td>S005001</td>\n",
       "      <td>5</td>\n",
       "      <td>Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>disgust</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dir  key_img  frame  \\\n",
       "0  extended-cohn-kanade-images\\cohn-kanade-images...  S005001      1   \n",
       "1  extended-cohn-kanade-images\\cohn-kanade-images...  S005001      2   \n",
       "2  extended-cohn-kanade-images\\cohn-kanade-images...  S005001      3   \n",
       "3  extended-cohn-kanade-images\\cohn-kanade-images...  S005001      4   \n",
       "4  extended-cohn-kanade-images\\cohn-kanade-images...  S005001      5   \n",
       "\n",
       "                                             dir_lbl  label cat_labels  \\\n",
       "0  Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...    0.0    neutral   \n",
       "1  Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...    0.0    neutral   \n",
       "2  Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...    0.0    neutral   \n",
       "3  Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...    3.0    disgust   \n",
       "4  Emotion_labels\\Emotion\\S005\\001\\S005_001_00000...    3.0    disgust   \n",
       "\n",
       "   reduced_labels  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3              -1  \n",
       "4              -1  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = pd.read_csv('base_clean_v2.csv')\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2691\n",
       " 1    1124\n",
       " 0     981\n",
       "Name: reduced_labels, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base['reduced_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para transformar o target da forma como o keras entende\n",
    "def map_keras_label(x):\n",
    "    if(x == -1):\n",
    "        # Negativos são 0\n",
    "        return 0\n",
    "    elif(x == 0):\n",
    "        # Neutros são 1\n",
    "        return 1\n",
    "    elif(x==1):\n",
    "        # Positivos são 2\n",
    "        return 2\n",
    "    else:\n",
    "        # Surprise é 3\n",
    "        return 3\n",
    "\n",
    "base['keras_labels'] = base['reduced_labels'].map(map_keras_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando base de treinamento e de validação\n",
    "train_dir, test_dir, y_train, y_test = train_test_split(base['dir'], base['keras_labels'], test_size = 0.2, random_state = 42,\n",
    "                                                       stratify = base['keras_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo funções para ler e preprocessar as imagens no tamanho desejado (100 x 100)\n",
    "size = 100\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.resize(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB), (size,size))\n",
    "#     img = cv2.addWeighted(img,4,cv2.GaussianBlur(img, (0,0), size/40) ,-4 ,128)\n",
    "    return img\n",
    "\n",
    "def load_test_image(path):\n",
    "    img = cv2.resize(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB), (size,size))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdbdd94c100465f8c1a4515571c4819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Defininto array de armazenamento das imagens\n",
    "images = np.empty((len(train_dir), size, size ,3), dtype = np.uint8)\n",
    "\n",
    "# Lendo as imagens e armazenando\n",
    "for i, path in tqdm_notebook(enumerate(train_dir)):\n",
    "    images[i,:,:,:] = load_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476deb77f4f84db4ac7ffd32286b48a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_images = np.empty((len(test_dir), size, size, 3), dtype = np.uint8)\n",
    "for i, path in tqdm_notebook(enumerate(test_dir)):\n",
    "    test_images[i,:,:, :] = load_test_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding targets\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Epoch 1/20\n",
      "239/240 [============================>.] - ETA: 2s - loss: 1.0189 - accuracy: 0.5482\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56250, saving model to vgg_100_100_20ep_da_2.h5\n",
      "240/240 [==============================] - 605s 3s/step - loss: 1.0190 - accuracy: 0.5480 - val_loss: 0.9450 - val_accuracy: 0.5625\n",
      "Epoch 2/20\n",
      "239/240 [============================>.] - ETA: 2s - loss: 0.9436 - accuracy: 0.5715\n",
      "Epoch 00002: val_accuracy improved from 0.56250 to 0.61458, saving model to vgg_100_100_20ep_da_2.h5\n",
      "240/240 [==============================] - 633s 3s/step - loss: 0.9425 - accuracy: 0.5719 - val_loss: 0.8514 - val_accuracy: 0.6146\n",
      "Epoch 3/20\n",
      "239/240 [============================>.] - ETA: 2s - loss: 0.7772 - accuracy: 0.6796\n",
      "Epoch 00003: val_accuracy improved from 0.61458 to 0.73958, saving model to vgg_100_100_20ep_da_2.h5\n",
      "240/240 [==============================] - 640s 3s/step - loss: 0.7768 - accuracy: 0.6799 - val_loss: 0.6386 - val_accuracy: 0.7396\n",
      "Epoch 4/20\n",
      "239/240 [============================>.] - ETA: 2s - loss: 0.6729 - accuracy: 0.7251\n",
      "Epoch 00004: val_accuracy improved from 0.73958 to 0.75104, saving model to vgg_100_100_20ep_da_2.h5\n",
      "240/240 [==============================] - 740s 3s/step - loss: 0.6732 - accuracy: 0.7242 - val_loss: 0.5886 - val_accuracy: 0.7510\n",
      "Epoch 5/20\n",
      "239/240 [============================>.] - ETA: 3s - loss: 0.6216 - accuracy: 0.7332\n",
      "Epoch 00005: val_accuracy improved from 0.75104 to 0.75521, saving model to vgg_100_100_20ep_da_2.h5\n",
      "240/240 [==============================] - 795s 3s/step - loss: 0.6214 - accuracy: 0.7333 - val_loss: 0.5782 - val_accuracy: 0.7552\n",
      "Epoch 6/20\n",
      "239/240 [============================>.] - ETA: 2s - loss: 0.5902 - accuracy: 0.7445\n",
      "Epoch 00006: val_accuracy improved from 0.75521 to 0.75833, saving model to vgg_100_100_20ep_da_2.h5\n",
      "240/240 [==============================] - 669s 3s/step - loss: 0.5900 - accuracy: 0.7445 - val_loss: 0.5644 - val_accuracy: 0.7583\n",
      "Epoch 7/20\n",
      "239/240 [============================>.] - ETA: 2s - loss: 0.5614 - accuracy: 0.7500\n",
      "Epoch 00007: val_accuracy improved from 0.75833 to 0.78125, saving model to vgg_100_100_20ep_da_2.h5\n",
      "240/240 [==============================] - 637s 3s/step - loss: 0.5607 - accuracy: 0.7503 - val_loss: 0.4874 - val_accuracy: 0.7812\n",
      "Epoch 8/20\n",
      "225/240 [===========================>..] - ETA: 37s - loss: 0.5462 - accuracy: 0.7659"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 100, 100\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "\n",
    "file_name = 'vgg_100_100_20ep_da_2.h5'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "vgg16 = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "# resnet = applications.resnet50.ResNet50(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height,3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "# for layer in resnet.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "model.add(vgg16)\n",
    "\n",
    "#Adding custom Layers \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# model.add(resnet)\n",
    "\n",
    "# #Adding custom Layers \n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(200, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(50, activation=\"relu\"))\n",
    "# model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# compile the model \n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.2,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=20)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.2,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=20)\n",
    "\n",
    "train_generator = train_datagen.flow(images, y_train, batch_size = 16 , seed = 42)\n",
    "\n",
    "validation_generator = test_datagen.flow(test_images, y_test, batch_size = 16,seed = 42)\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(file_name, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# # Train the model \n",
    "# model.fit_generator(\n",
    "# train_generator,\n",
    "# steps_per_epoch = nb_train_samples,\n",
    "# epochs = epochs,\n",
    "# validation_data = validation_generator,\n",
    "# nb_val_samples = nb_validation_samples,\n",
    "# callbacks = [checkpoint, early])\n",
    "\n",
    "\n",
    "model.fit_generator(generator = train_generator,\n",
    "                    steps_per_epoch = len(train_generator),\n",
    "                    epochs = epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    callbacks = [checkpoint, early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"Perda de treino e teste\")\n",
    "plt.plot(model.history.history['loss'], label = \"Treino\")\n",
    "plt.plot(model.history.history['val_loss'], label = \"Teste\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"Acurácia de treino e teste\")\n",
    "plt.plot(model.history.history['accuracy'],label = \"Treino\")\n",
    "plt.plot(model.history.history['val_accuracy'], label = \"Teste\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando modelo para testes (porém o ideal é utilizar o que salva automaticamente)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo em um json para reutilizá-lo\n",
    "model_json = model.to_json()\n",
    "with open(\"model_v2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preditos = model.predict(np.array(test_images, dtype=np.float)).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test.argmax(axis=1), y_preditos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test.argmax(axis=1), y_preditos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test.argmax(axis=1), y_preditos, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
